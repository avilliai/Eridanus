import aiosqlite
import json
import asyncio
import redis
import time

from developTools.utils.logger import get_logger
from run.ai_llm.service.aiReplyHandler.gemini import gemini_prompt_elements_construct
from run.ai_llm.service.aiReplyHandler.openai import prompt_elements_construct, prompt_elements_construct_old_version

DB_NAME = "data/dataBase/group_messages.db"
def is_running_in_docker():
    return os.path.exists("/.dockerenv") or os.environ.get("IN_DOCKER") == "1"

if is_running_in_docker():
    REDIS_URL = "redis://redis:6379/0"
else:
    REDIS_URL = "redis://localhost"
REDIS_CACHE_TTL = 60  # ç§’

logger = get_logger()

redis_client = None
import os
import subprocess
import platform
import zipfile

REDIS_EXECUTABLE = "redis-server.exe"
REDIS_ZIP_PATH = os.path.join("data", "Redis-x64-5.0.14.1.zip")
REDIS_FOLDER = os.path.join("data", "redis_extracted")


def extract_redis_from_local_zip():
    """ä»æœ¬åœ° zip è§£å‹ Redis åˆ°æŒ‡å®šç›®å½•"""
    if not os.path.exists(REDIS_FOLDER):
        os.makedirs(REDIS_FOLDER)
        logger.info("ğŸ“¦ æ­£åœ¨ä»æœ¬åœ°å‹ç¼©åŒ…è§£å‹ Redis...")
        with zipfile.ZipFile(REDIS_ZIP_PATH, 'r') as zip_ref:
            zip_ref.extractall(REDIS_FOLDER)
        logger.info("âœ… Redis è§£å‹å®Œæˆ")


def start_redis_background():
    """åœ¨åå°å¯åŠ¨ Redisï¼ˆä»…æ”¯æŒ Windowsï¼‰"""
    extract_redis_from_local_zip()
    redis_path = os.path.join(REDIS_FOLDER, REDIS_EXECUTABLE)
    if not os.path.exists(redis_path):
        logger.error(f"âŒ æ‰¾ä¸åˆ° redis-server.exe äº {redis_path}")
        return

    logger.info("ğŸš€ å¯åŠ¨ Redis æœåŠ¡ä¸­...")
    subprocess.Popen([redis_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# åˆå§‹åŒ– Redis å®¢æˆ·ç«¯
def init_redis():
    global redis_client
    if redis_client is not None:
        return

    try:
        redis_client = redis.StrictRedis.from_url(REDIS_URL, decode_responses=True)
        redis_client.ping()
        logger.info("âœ… Redis è¿æ¥æˆåŠŸ")
    except redis.exceptions.ConnectionError:
        logger.warning("âš ï¸ Redis æœªè¿è¡Œï¼Œå°è¯•è‡ªåŠ¨å¯åŠ¨ Redis...")
        if platform.system() == "Windows":
            start_redis_background()
            time.sleep(2)
            try:
                redis_client = redis.StrictRedis.from_url(REDIS_URL, decode_responses=True)
                redis_client.ping()
                logger.info("âœ… Redis å·²è‡ªåŠ¨å¯åŠ¨å¹¶è¿æ¥æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ Redis å¯åŠ¨å¤±è´¥ï¼š{e}")
                redis_client = None
        else:
            logger.error("âŒ é Windows ç³»ç»Ÿï¼Œè¯·æ‰‹åŠ¨å®‰è£…å¹¶å¯åŠ¨ Redis")
            redis_client = None


init_redis()
# ======================= é€šç”¨å‡½æ•° =======================
MAX_RETRIES = 2
INITIAL_DELAY = 2


async def execute_with_retry(db, query, params=None):
    """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®åº“æ“ä½œ"""
    for attempt in range(MAX_RETRIES):
        try:
            if params:
                await db.execute(query, params)
            else:
                await db.execute(query)
            return
        except aiosqlite.OperationalError as e:
            if "database is locked" in str(e):
                delay = INITIAL_DELAY * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logger.info(f"Database is locked. Retrying in {delay:.2f} seconds...")
                await asyncio.sleep(delay)
            else:
                raise
    raise Exception(f"Max retries reached. Database still locked after {MAX_RETRIES} attempts.")


# ======================= åˆå§‹åŒ– =======================
async def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œæ£€æŸ¥å¹¶æ·»åŠ å¿…è¦çš„å­—æ®µ"""
    async with aiosqlite.connect(DB_NAME) as db:
        try:
            await execute_with_retry(db, """
                CREATE TABLE IF NOT EXISTS group_messages (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    group_id INTEGER NOT NULL,
                    message TEXT NOT NULL,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    processed_message TEXT,
                    new_openai_processed_message TEXT,
                    old_openai_processed_message TEXT
                )
            """)

            # WAL æ¨¡å¼ï¼Œæé«˜å¹¶å‘æ€§èƒ½
            await db.execute("PRAGMA journal_mode=WAL;")
            await db.commit()

        except Exception as e:
            logger.warning(f"Error initializing database: {e}")


# åˆå§‹åŒ–æ•°æ®åº“
asyncio.run(init_db())


# ======================= æ·»åŠ æ¶ˆæ¯ =======================
async def add_to_group(group_id: int, message, delete_after: int = 50):
    """å‘ç¾¤ç»„æ·»åŠ æ¶ˆæ¯ï¼ˆæ’å…¥æ•°æ®åº“å¹¶æ›´æ–° Redisï¼‰"""
    init_redis()
    async with aiosqlite.connect(DB_NAME) as db:
        try:
            cursor = await db.execute("SELECT COUNT(*) FROM group_messages WHERE group_id =?", (group_id,))
            count = (await cursor.fetchone())[0]

            if count >= delete_after:
                excess_count = count - delete_after + 1
                await execute_with_retry(
                    db,
                    "DELETE FROM group_messages WHERE id IN (SELECT id FROM group_messages WHERE group_id =? ORDER BY timestamp ASC LIMIT?)",
                    (group_id, excess_count)
                )
                await db.commit()

            await execute_with_retry(
                db,
                "INSERT INTO group_messages (group_id, message, processed_message, new_openai_processed_message, old_openai_processed_message) VALUES (?,?, NULL, NULL, NULL)",
                (group_id, json.dumps(message))
            )
            await db.commit()

            for k in ["gemini", "new_openai", "old_openai"]:
                redis_client.delete(f"group:{group_id}:{k}")

        except Exception as e:
            logger.info(f"Error adding to group {group_id}: {e}")
            
async def get_group_messages(group_id: int, limit: int = 50):
    """è·å–æŒ‡å®šç¾¤ç»„çš„æŒ‡å®šæ•°é‡æ¶ˆæ¯ï¼Œä»…è¿”å›æ–‡æœ¬çš„åˆ—è¡¨"""
    try:
        query = "SELECT message FROM group_messages WHERE group_id =? ORDER BY timestamp DESC"
        params = (group_id,)
        if limit is not None:
            query += " LIMIT?"
            params += (limit,)

        async with aiosqlite.connect(DB_NAME) as db:
            cursor = await db.execute(query, params)
            rows = await cursor.fetchall()
            text_list = []
            for row in rows:
                try:
                    raw_message = json.loads(row[0])
                    if "message" in raw_message and isinstance(raw_message["message"], list):
                        for msg_obj in raw_message["message"]:
                            if isinstance(msg_obj, dict) and "text" in msg_obj and isinstance(msg_obj["text"], str):
                                text_list.append(msg_obj["text"])
                except (json.JSONDecodeError, KeyError):
                    pass
            return text_list
    except Exception as e:
        logger.info(f"Error getting messages for group {group_id}: {e}")
        return []


# ======================= è·å–å¹¶è½¬æ¢æ¶ˆæ¯ =======================
async def get_last_20_and_convert_to_prompt(group_id: int, data_length=20, prompt_standard="gemini", bot=None,
                                            event=None):
    """è·å–æœ€è¿‘çš„æ¶ˆæ¯å¹¶è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼çš„ prompt"""
    init_redis()
    cache_key = f"group:{group_id}:{prompt_standard}"

    # å°è¯•ä» Redis è·å–ç¼“å­˜
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # æ˜ å°„ä¸åŒçš„æ ‡å‡†å­—æ®µ
    field_mapping = {
        "gemini": "processed_message",
        "new_openai": "new_openai_processed_message",
        "old_openai": "old_openai_processed_message"
    }

    if prompt_standard not in field_mapping:
        raise ValueError(f"ä¸æ”¯æŒçš„ prompt_standard: {prompt_standard}")

    selected_field = field_mapping[prompt_standard]

    # ä»æ•°æ®åº“ä¸­è·å–æ¶ˆæ¯
    async with aiosqlite.connect(DB_NAME) as db:
        try:
            cursor = await db.execute(
                f"SELECT id, message, {selected_field} FROM group_messages WHERE group_id = ? ORDER BY timestamp DESC LIMIT ?",
                (group_id, data_length)
            )
            rows = await cursor.fetchall()

            final_list = []
            for row in rows:
                message_id, raw_message, processed_message = row
                raw_message = json.loads(raw_message)

                # å¦‚æœå·²ç»å¤„ç†è¿‡ï¼Œä½¿ç”¨ç¼“å­˜çš„æ¶ˆæ¯
                if processed_message:
                    final_list.append(json.loads(processed_message))
                else:
                    raw_message["message"].insert(0, {
                        "text": f"æœ¬æ¡æ¶ˆæ¯æ¶ˆæ¯å‘é€è€…ä¸º {raw_message['user_name']} idä¸º{raw_message['user_id']} è¿™æ˜¯å‚è€ƒæ¶ˆæ¯ï¼Œå½“æˆ‘å†æ¬¡å‘ä½ æé—®æ—¶ï¼Œè¯·æ­£å¸¸å›å¤æˆ‘ã€‚"
                    })

                    if prompt_standard == "gemini":
                        processed = await gemini_prompt_elements_construct(raw_message["message"], bot=bot, event=event)
                        final_list.append(processed)
                    elif prompt_standard == "new_openai":
                        processed = await prompt_elements_construct(raw_message["message"], bot=bot, event=event)
                        final_list.append(processed)
                        final_list.append(
                            {"role": "assistant", "content": [{"type": "text", "text": "(ç¾¤èŠèƒŒæ™¯æ¶ˆæ¯å·²è®°å½•)"}]})
                    else:
                        processed = await prompt_elements_construct_old_version(raw_message["message"], bot=bot,
                                                                                event=event)
                        final_list.append(processed)
                        final_list.append({"role": "assistant", "content": "(ç¾¤èŠèƒŒæ™¯æ¶ˆæ¯å·²è®°å½•)"})

                    # æ›´æ–°æ•°æ®åº“
                    await execute_with_retry(
                        db,
                        f"UPDATE group_messages SET {selected_field} = ? WHERE id = ?",
                        (json.dumps(processed), message_id)
                    )
                    await db.commit()

            # å¤„ç†æœ€ç»ˆæ ¼å¼åŒ–çš„æ¶ˆæ¯
            fl = []
            if prompt_standard == "gemini":
                all_parts = [part for entry in final_list if entry['role'] == 'user' for part in entry['parts']]
                fl.append({"role": "user", "parts": all_parts})
                fl.append({"role": "model", "parts": {"text": "å—¯å—¯ï¼Œæˆ‘è®°ä½äº†"}})
            else:
                all_parts = []
                all_parts_str = ""
                for entry in final_list:
                    if entry['role'] == 'user':
                        if isinstance(entry['content'], str):
                            all_parts_str += entry['content'] + "\n"
                        else:
                            for part in entry['content']:
                                all_parts.append(part)
                fl.append({"role": "user", "content": all_parts if all_parts else all_parts_str})
                fl.append({"role": "assistant", "content": "å—¯å—¯æˆ‘è®°ä½äº†"})

            # è®¾ç½®ç¼“å­˜
            redis_client.setex(cache_key, REDIS_CACHE_TTL, json.dumps(fl))
            return fl

        except Exception as e:
            logger.info(f"Error getting last 20 and converting to prompt for group {group_id}: {e}")
            return []


# ======================= æ¸…é™¤æ¶ˆæ¯ =======================
async def clear_group_messages(group_id: int):
    """æ¸…é™¤æŒ‡å®šç¾¤ç»„çš„æ‰€æœ‰æ¶ˆæ¯"""
    init_redis()
    async with aiosqlite.connect(DB_NAME) as db:
        try:
            await execute_with_retry(
                db,
                "DELETE FROM group_messages WHERE group_id = ?",
                (group_id,)
            )
            await db.commit()
            logger.info(f"âœ… å·²æ¸…é™¤ group_id={group_id} çš„æ‰€æœ‰æ•°æ®")

            # æ¸…é™¤æ‰€æœ‰ prompt æ ‡å‡†çš„ç¼“å­˜
            for k in ["gemini", "new_openai", "old_openai"]:
                redis_client.delete(f"group:{group_id}:{k}")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç† group_id={group_id} æ•°æ®æ—¶å‡ºé”™: {e}")
